A. 3 states (Enhancement 3 does not work)
There are 3 states: S1,S2,S3

0.75		64	48
0.5625		64	36
0.421875	64	27

Approach1 => 4 iterations
R33=16 => V1(S3)=64
R22=1 => V1(S2) = 1
R11=1 => V1(S1) = 1

Enhancement1 => 5 iterations
Add action from S3 to S1, such that at the beginning A33 is better, but at the end, when V(S0) is set, A30 is better.
The conditions must be: 
	R30 < V1(S3) + R33 (the value of S3 after A30 to be less than this value + R33 - such that at second step action A33 is taken) 
	R30+0.75*V(S1) > V(S3) (the value of R30 + discounted value of S1 > the current value of S3, such that at the last step the action A30 is taken)
	
	Solving the above:
	R30 < R30 + R33 => any R30 works
	R30 + 0.75^3*4*R33 > 4*R33
	R30 > 4*R33 - 0.75^3*4*R33 => R30 > 64 - 0.75^3*64 => R30 > 37
Conclusion: R30 can be a number as high as required, but bigger then 37 -> Vf(S3) can be made arbitrarily high, according to further enhancements requirements	


Enhancement3: Does not work
After S3 best action goes to S1, how to make that the action A11 becomes best action for A1?
If instead of A11, we make the action stochastic: A1_13: goes to 1 with some p1 and r1 and goes to 3 with some p2 and r2.
There are 2 restrictions needed:
1. A1_13 is worse than A12, as long as the best action for S3 is A33.
2. A1_13 is better than A12, after the best action for S3 becomes A30

The equations for the above are:
1.Vi(S0) + evaluate(A1_13) < Vi(S0) + evaluate(A12) - when best action for S3 = A33
2.Vi(S0) + evaluate(A1_13) < Vi(S0) + evaluate(A12) - when best action for S3 becomes A30

1. p1*(r1 + 0.75*Vi(S1)) + p2(r2 + 0.75*Vintermediar(S3)) < 0.75 * 0.75 * Vintermediar(S3)
2. p1*(r1 + 0.75*Vintermediar(S1)) + p2(r2 + 0.75*Vf(S3)) > 0.75 * 0.75 * Vf(S3)

1. p1*r1 + p2(r2 + 0.75*64) < 0.75*0.75*64
2. p1*(r1 + 0.75^3*64) + p2(r2 + Vf(S3)) > 0.75*0.75*Vf(S3)

See in excel a 'solver' for the above equations.

Why it does not work: If there is cycle: S1->S3 and S3->S1 => the values of S1 and S3 will be equal, and equal to the rewards*4 => the rest will not work as expected (e.g. A1_13 will stay as best action)

===========================================
B. 4 States

Approach1 => 5 iterations
R44=256
R11 = R22 = R33 = 1

At the beginning, for each state, the best action is to go to itself.
Then, after S4 value is set to 256*4, one by one the best action for states S3,S2 and S1 will be changed from going to itself to going to the next node.


Enhancement1 => 6 iterations
Add action from S4 to S1, such that at the beginning A44 is better, but at the end, when V(S1) is set, A41 is better.
The conditions must be: 
	R41 < Vi(S4) + R44 (the value of S4 after A41 to be less than this value + R44 - such that at second step action A44 is taken) 
	R41 + 0.75*Vf(S1) > V(S4) (the value of R41 + discounted value of Vf(S1)  > the current value of S4, such that at the last step the action A41 is taken)
	
	Solving the above:
	R41 < R41 + R44 => any R30 works
	R41 + 0.75^4*4*R44 > 4*R44
	R41 > 4*R44 - 0.75^4*4*R44 => R41 > 1024 - 0.75^4*1024 => R41 > 700
Conclusion: R41 can be a number as high as required, but bigger then 700 -> Vf(S4) can be made arbitrarily high, according to further enhancements requirements	

Enhancement2
After the last increase in value of S4, let's try to make S2 have a better outcome if would take the action: A2_24.
Why this should work?
	Before the increment of V(S4), best action of S2 is A23. This action makes that V(S2)=lambda^2 * Vintermediar(S4)
	If we would have a stochastic action A2_24 with enough weight of S4, lets try to write the inequalities:
	
	Before the final update of S4, A23 is the best option. After the final update, A2_24 must become the best option:
	
	p1*(r1 + 0.75*Vintermediar(S2)) + p2*(r2 + 0.75*Vintermediar(S4)) < 0.75^2*Vintermediar(S4)
	p1*(r1 + 0.75*Vintermediar1(S2)) + p2*(r2 + 0.75*Vfinal(S4)) > 0.75*2*Vfinal(S4)
	
	p1*(r1 + 0.75^3*1024) + p2*(r2 + 0.75*1024)) < 0.75^2 * 1024
	p1*(r1 + 0.75^3*Vf(S4)) + p2*(r2 + 0.75*Vf(S4))) > 0.75^2 * Vf(S4)
	
	p1*(r1+432) + p2*(r2+768) < 576
	p1*(r1 + 0.75^3*Vf(S4)) + p2*(r2 + 0.75*Vf(S4))) > 0.75^2 * Vf(S4)
	
	
	
